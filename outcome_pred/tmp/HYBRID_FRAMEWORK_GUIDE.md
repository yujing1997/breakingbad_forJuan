# Hybrid Multimodal Survival Prediction Framework

## ğŸ¯ Overview

This framework implements two complementary approaches for HECKTOR 2025 Task 2 survival prediction:

1. **Organizer's Direct Fusion**: Proven baseline with DenseNet121 upgrade
2. **Enhanced Multimodal**: Advanced VAE + Attention fusion strategies

Both approaches use **DenseNet121** backbone (upgraded from ResNet-18) for superior feature extraction.

## ğŸ“‹ Table of Contents

- [Preprocessing Pipeline](#preprocessing-pipeline)
- [Architecture Diagrams](#architecture-diagrams)
- [Implementation Details](#implementation-details)
- [Usage Examples](#usage-examples)
- [Performance Comparison](#performance-comparison)

---

## ğŸ”„ Preprocessing Pipeline

### 1. Image Preprocessing Flow

```
Raw DICOM/NIfTI Images
         â†“
    Registration & Resampling
         â†“
    Intensity Normalization
         â†“
    Cropping & Resizing
         â†“
    Data Augmentation (Training)
         â†“
    Tensor Conversion
```

### 2. Detailed Preprocessing Steps

#### Step 1: Image Loading & Registration
```python
# Load CT and PET images
ct_image = sitk.ReadImage(ct_path)      # Original resolution
pet_image = sitk.ReadImage(pet_path)    # Original resolution

# Register PET to CT space (if needed)
if not same_geometry(ct_image, pet_image):
    pet_image = register_images(pet_image, ct_image)
```

#### Step 2: Intensity Normalization
```python
# CT normalization: Clip and normalize to [-1, 1]
ct_array = sitk.GetArrayFromImage(ct_image)
ct_clipped = np.clip(ct_array, -1000, 1000)  # HU clipping
ct_normalized = (ct_clipped + 1000) / 2000.0 * 2.0 - 1.0

# PET normalization: Z-score normalization
pet_array = sitk.GetArrayFromImage(pet_image)
pet_normalized = (pet_array - pet_array.mean()) / (pet_array.std() + 1e-8)
```

#### Step 3: Spatial Processing
```python
# Target size for both approaches
TARGET_SIZE = (96, 96, 96)  # [H, W, D]

# Resample to isotropic spacing (1mmÂ³)
resampler = sitk.ResampleImageFilter()
resampler.SetSize(TARGET_SIZE)
resampler.SetOutputSpacing([1.0, 1.0, 1.0])

ct_resampled = resampler.Execute(ct_image)
pet_resampled = resampler.Execute(pet_image)
```

#### Step 4: Region-Based Cropping (Enhanced Approach Only)
```python
# For enhanced approach: segment and crop around tumors
segmentator = Segmentator()
segmentation = segmentator.predict(ct_image, pet_image)

# Find connected components
labeled_array, num_components = label(segmentation > 0)

# Crop around each component with margin
for component_id in range(1, num_components + 1):
    mask = (labeled_array == component_id)
    cropped_ct = crop_around_mask(ct_resampled, mask, margin_mm=10.0)
    cropped_pet = crop_around_mask(pet_resampled, mask, margin_mm=10.0)
```

### 3. Clinical Data Preprocessing

```python
# Clinical features preprocessing
clinical_features = [
    'Age',                    # Continuous: normalized to [0, 1]
    'Gender',                 # Binary: M=1, F=0
    'Tobacco Consumption',    # Categorical: encoded [0, 1, 2]
    'Alcohol Consumption',    # Binary: Yes=1, No=0
    'Performance Status',     # Ordinal: [0, 1, 2, 3, 4]
    'Treatment',              # Categorical: one-hot encoded
    'M-stage',               # Categorical: M0=0, M1=1
    'N-stage',               # Ordinal: [0, 1, 2, 3]
    'T-stage',               # Ordinal: [1, 2, 3, 4]
    'Overall_stage',         # Ordinal: [1, 2, 3, 4]
    'Subsite',               # Categorical: one-hot encoded
    'GTVt_volume',           # Continuous: log-normalized
    'GTVn_volume'            # Continuous: log-normalized
]

# Normalization
scaler = StandardScaler()
clinical_normalized = scaler.fit_transform(clinical_features)
```

---

## ğŸ—ï¸ Architecture Diagrams

### 1. Organizer's Direct Fusion Approach

```
INPUT STAGE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CT Images  â”‚    â”‚ PET Images  â”‚
â”‚ [1,96,96,96]â”‚    â”‚ [1,96,96,96]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Concatenate   â”‚
        â”‚  [2,96,96,96]   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
FEATURE EXTRACTION:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   DenseNet121   â”‚
        â”‚  (2 channels)   â”‚
        â”‚      â†“          â”‚
        â”‚  [batch, 1024]  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
CLINICAL PROCESSING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Clinical Dataâ”‚  â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ Neural Network  â”‚
â”‚ [batch, 13] â”‚           â”‚ 13â†’64â†’64â†’32     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  [batch, 32]    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
FUSION STAGE:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Feature Fusion          â”‚
        â”‚ [1024 + 32] â†’ 512 â†’ 256     â”‚
        â”‚        [batch, 128]         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
OUTPUT STAGE:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Risk Prediction        â”‚
        â”‚    128 â†’ 64 â†’ 1            â”‚
        â”‚     [batch, 1]             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Enhanced Multimodal Approach

```
INPUT STAGE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CT Images  â”‚              â”‚ PET Images  â”‚
â”‚ [1,96,96,96]â”‚              â”‚ [1,96,96,96]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                            â”‚
       â–¼                            â–¼
SEPARATE FEATURE EXTRACTION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DenseNet121 â”‚              â”‚ DenseNet121 â”‚
â”‚ (CT branch) â”‚              â”‚ (PET branch)â”‚
â”‚ [batch,512] â”‚              â”‚ [batch,512] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
ADVANCED FUSION STRATEGIES:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                VAE FUSION                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚CT Encoder   â”‚    â”‚PET Encoder  â”‚             â”‚
â”‚  â”‚512â†’256â†’128  â”‚    â”‚512â†’256â†’128  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                  â”‚                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                  â–¼                             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚         â”‚  Î¼, Ïƒ Estimationâ”‚                    â”‚
â”‚         â”‚   [batch, 64]   â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                  â”‚                             â”‚
â”‚                  â–¼                             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚         â”‚ Reparameterize  â”‚                    â”‚
â”‚         â”‚   [batch, 64]   â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ATTENTION FUSION                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚CT Projectionâ”‚    â”‚PET Projectionâ”‚            â”‚
â”‚  â”‚   512â†’64    â”‚    â”‚   512â†’64     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                  â”‚                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                  â–¼                             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚         â”‚ Attention Weightsâ”‚                   â”‚
â”‚         â”‚   [batch, 2]    â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                  â”‚                             â”‚
â”‚                  â–¼                             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚         â”‚Weighted Featuresâ”‚                    â”‚
â”‚         â”‚   [batch, 64]   â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CLINICAL PROCESSING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Clinical Dataâ”‚  â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ Neural Network  â”‚
â”‚ [batch, 13] â”‚           â”‚ 13â†’64â†’64â†’32     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  [batch, 32]    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FINAL FUSION:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         Combined Features           â”‚
        â”‚ [VAE:64 + Attention:64 + Clinical:32]â”‚
        â”‚        [batch, 160] â†’ 128           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
OUTPUT STAGE:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Risk Prediction        â”‚
        â”‚    128 â†’ 64 â†’ 1            â”‚
        â”‚     [batch, 1]             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Training Flow Comparison

```
ORGANIZER'S TRAINING FLOW:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Data  â”‚ â†’  â”‚ Train DenseNet  â”‚ â†’  â”‚Extract Features â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evaluate   â”‚ â†  â”‚Train BaggedIcareâ”‚ â†  â”‚ Prepare Dataset â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ENHANCED TRAINING FLOW:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Region Segmentâ”‚ â†’ â”‚  Train VAE      â”‚ â†’  â”‚Train Attention  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                      â”‚
       â–¼                    â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Crop Regions â”‚    â”‚VAE Loss (MSE+KL)â”‚    â”‚Attention Weightsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                      â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Joint Feature Training â”‚
              â”‚  (Survival + VAE Loss)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Train BaggedIcare     â”‚
              â”‚   (Enhanced Features)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Implementation Details

### 1. Key Classes and Components

```python
# Core Architecture Classes
class OrganizerFeatureExtractor(nn.Module):
    """Direct CT+PET fusion with DenseNet121"""
    - imaging_backbone: DenseNet121(in_channels=2)
    - clinical_processor: 13â†’64â†’64â†’32
    - feature_fusion: (1024+32)â†’512â†’256â†’128
    - risk_head: 128â†’64â†’1

class EnhancedMultimodalFeatureExtractor(nn.Module):
    """Separate processing + advanced fusion"""
    - ct_backbone: DenseNet121(in_channels=1)
    - pet_backbone: DenseNet121(in_channels=1)
    - vae_fusion: VAEFusion(512, 512, 64)
    - attention_fusion: AttentionWeightedFusion(512, 512, 64)
    - feature_fusion: (64+64+32)â†’256â†’128

class HybridSurvivalModel(nn.Module):
    """Unified model supporting both approaches"""
    - use_organizer_approach: bool flag
    - feature_extractor: Either organizer or enhanced
    - icare_model: BaggedIcareSurvival backend
```

### 2. Loss Functions

#### Organizer's Approach
```python
# Simple survival loss
survival_loss = DeepHitLoss(ranking_weight=0.3)
total_loss = survival_loss(risk_scores, survival_times, events)
```

#### Enhanced Approach
```python
# Multi-component loss
survival_loss = DeepHitLoss(ranking_weight=0.3)
vae_loss = reconstruction_loss + kl_divergence_loss
contrastive_loss = SurvivalContrastiveLoss(margin=2.0)

total_loss = (survival_loss + 
              0.1 * vae_loss + 
              0.1 * contrastive_loss)
```

### 3. Data Flow

#### Input Formats
```python
# For Organizer's Approach
combined_images: [batch, 2, 96, 96, 96]  # CT+PET concatenated
clinical_features: [batch, 13]
survival_times: [batch]
events: [batch]

# For Enhanced Approach  
ct_images: [batch, 1, 96, 96, 96]        # Separate CT
pet_images: [batch, 1, 96, 96, 96]       # Separate PET
clinical_features: [batch, 13]
survival_times: [batch]
events: [batch]
```

#### Feature Dimensions
```python
# Organizer's Feature Flow
CT+PET [2,96,96,96] â†’ DenseNet121 â†’ [1024]
Clinical [13] â†’ MLP â†’ [32]
Combined [1024+32] â†’ Fusion â†’ [128]

# Enhanced Feature Flow
CT [1,96,96,96] â†’ DenseNet121 â†’ [512]
PET [1,96,96,96] â†’ DenseNet121 â†’ [512]
VAE Fusion: [512+512] â†’ [64]
Attention Fusion: [512+512] â†’ [64]
Clinical [13] â†’ MLP â†’ [32]
Combined [64+64+32] â†’ Fusion â†’ [128]
```

---

## ğŸ’» Usage Examples

### 1. Quick Start - Organizer's Approach

```python
from hybrid_multimodal_survival import HybridSurvivalModel

# Initialize model with organizer's approach
model = HybridSurvivalModel(
    clinical_feature_dim=13,
    use_organizer_approach=True,  # Key flag
    device=torch.device('cuda')
)

# Training
for batch in train_loader:
    # Combine CT and PET at input level
    ct_images = batch['ct']      # [batch, 1, 96, 96, 96]
    pet_images = batch['pet']    # [batch, 1, 96, 96, 96]
    combined = torch.cat([ct_images, pet_images], dim=1)
    
    risk_scores = model(
        combined_images=combined,
        clinical_features=batch['clinical']
    )
```

### 2. Advanced Usage - Enhanced Approach

```python
# Initialize model with enhanced fusion
model = HybridSurvivalModel(
    clinical_feature_dim=13,
    use_organizer_approach=False,  # Use advanced approach
    use_vae_fusion=True,
    use_attention_fusion=True,
    device=torch.device('cuda')
)

# Training with separate modality processing
for batch in train_loader:
    risk_scores = model(
        ct_images=batch['ct'],      # Separate CT processing
        pet_images=batch['pet'],    # Separate PET processing  
        clinical_features=batch['clinical']
    )
```

### 3. Comparative Training

```python
# Compare both approaches
results = run_comparative_experiment(
    train_loader=train_loader,
    val_loader=val_loader,
    clinical_feature_dim=13,
    device=torch.device('cuda')
)

print(f"Organizer approach: {results['organizer']['val_loss']:.4f}")
print(f"Enhanced approach: {results['enhanced']['val_loss']:.4f}")
```

### 4. Hyperparameter Optimization

```python
# Using Optuna for optimization
def objective(trial):
    model = HybridSurvivalModel(
        use_organizer_approach=False  # Optimize enhanced approach
    )
    
    features, val_loss = model.train_neural_features(
        train_loader, val_loader, trial=trial
    )
    return val_loss

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)
```

---

## ğŸ“Š Performance Comparison

### 1. Expected Performance Characteristics

| Metric | Organizer's Approach | Enhanced Approach |
|--------|---------------------|-------------------|
| **Training Speed** | âš¡ 2-3x faster | ğŸŒ Baseline |
| **Memory Usage** | ğŸ’š ~50% less | ğŸ“ˆ Baseline |
| **Parameter Count** | ğŸ’š ~12M parameters | ğŸ“ˆ ~24M parameters |
| **Feature Quality** | âœ… Good baseline | ğŸš€ Potentially superior |
| **Overfitting Risk** | ğŸ’š Lower | âš ï¸ Moderate |
| **Interpretability** | âœ… Simpler | ğŸ” More complex |

### 2. When to Use Each Approach

#### Use Organizer's Approach When:
- âœ… Limited computational resources
- âœ… Smaller datasets (< 500 patients)
- âœ… Need fast training/inference
- âœ… Want proven, stable results
- âœ… Baseline comparison needed

#### Use Enhanced Approach When:
- ğŸš€ Sufficient computational resources
- ğŸš€ Larger datasets (> 500 patients)
- ğŸš€ Pushing performance boundaries
- ğŸš€ Analyzing multimodal interactions
- ğŸš€ Research/publication goals

### 3. Architecture Benefits

#### Organizer's Benefits:
- **Simplicity**: Straightforward implementation
- **Stability**: Fewer failure modes
- **Efficiency**: Lower resource requirements
- **Proven**: Based on competition-winning approach

#### Enhanced Benefits:
- **Flexibility**: Separate modality processing
- **Sophistication**: Advanced fusion strategies
- **Interpretability**: Attention weights show modality importance
- **Extensibility**: Easy to add new fusion methods

---

## ğŸ”§ Configuration Options

### 1. Model Configuration

```python
# Organizer's Configuration
organizer_config = {
    'use_organizer_approach': True,
    'clinical_feature_dim': 13,
    'feature_dim': 128,
    'imaging_backbone': 'densenet121',
    'fusion_strategy': 'direct_concatenation'
}

# Enhanced Configuration  
enhanced_config = {
    'use_organizer_approach': False,
    'clinical_feature_dim': 13,
    'feature_dim': 128,
    'vae_latent_dim': 64,
    'use_vae_fusion': True,
    'use_attention_fusion': True,
    'imaging_backbone': 'densenet121'
}
```

### 2. Training Configuration

```python
# Standard Training
training_config = {
    'epochs': 50,
    'batch_size': 4,
    'learning_rate': 1e-3,
    'weight_decay': 1e-5,
    'scheduler_patience': 3
}

# Hyperparameter Optimization
optuna_config = {
    'n_trials': 50,
    'cv_folds': 3,
    'pruning': True,
    'optimize_params': [
        'lr', 'weight_decay', 'ranking_weight',
        'vae_loss_weight', 'attention_dim'
    ]
}
```

### 3. Data Configuration

```python
# Preprocessing Configuration
preprocess_config = {
    'target_size': (96, 96, 96),
    'target_spacing': (1.0, 1.0, 1.0),
    'ct_clip_range': (-1000, 1000),
    'normalization': 'z_score',
    'augmentation': True,
    'region_margin_mm': 10.0
}
```

---

## ğŸš€ Next Steps

1. **Data Preparation**: Set up your HECKTOR dataset following the preprocessing pipeline
2. **Environment Setup**: Install dependencies (`pip install -r requirements.txt`)
3. **Model Selection**: Choose between organizer's or enhanced approach based on your resources
4. **Training**: Run comparative experiments to determine best approach for your data
5. **Optimization**: Use Optuna for hyperparameter tuning
6. **Evaluation**: Validate on test set and analyze results

---

*This framework provides a complete solution for HECKTOR 2025 Task 2, combining proven methods with advanced research techniques. Choose the approach that best fits your computational resources and performance requirements.*
